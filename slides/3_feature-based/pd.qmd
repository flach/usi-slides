---
title: "Partial Dependence (PD)"
subtitle: "(Feature Influence)"
---

```{python}
#| echo: false
#| output: false

# Handle imports and setup
import scipy
import sklearn.datasets
import sklearn.inspection
import sklearn.tree
import sklearn.svm
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

plt.style.use('seaborn')
```

```{python}
#| echo: false
#| output: false

# Get data and model ready
# Iris -- numerical
data_dict = sklearn.datasets.load_iris()
feature_names, target_names = data_dict['feature_names'], data_dict['target_names']

X_num, y_num = data_dict['data'], data_dict['target']
clf_num = sklearn.svm.SVC(probability=True)
clf_num.fit(X_num, y_num)

# Iris -- categorical
X_cat, y_cat = np.array(X_num), y_num
_map = X_num[:, 3] < 0.8
X_cat[_map, 3] = 0
_map = np.logical_and((X_num[:, 3] >= 0.8), (X_num[:, 3] < 1.35))
X_cat[_map, 3] = 1
_map = X_num[:, 3] >= 1.35
X_cat[_map, 3] = 2
cat_map = {0: 'low (x<0.8)', 1: 'medium (0.8≤x<1.35)', 2: 'high (1.35≤x)'}
clf_cat = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=10)
clf_cat.fit(X_cat, y_cat)
```

```{python}
#| echo: false
#| output: false

def update_colours(dark=False):
    solarized_dark = '#e4dbbd'
    solarized_light = '#002b36'
    colour = solarized_dark if dark else solarized_light
    mpl.rcParams.update({
        'text.color' : colour,
        'axes.labelcolor' : colour,
        'xtick.color': colour,
        'ytick.color': colour})

update_colours()
line_colour = plt.rcParams['axes.prop_cycle'].by_key()['color'][0]
other_colour = plt.rcParams['axes.prop_cycle'].by_key()['color'][1]
```

# Method Overview

## Explanation Synopsis

<br>

> PD captures the **average response of a predictive model** for
> a **collection of instances** when **varying one of their features**
> [@friedman2001greedy].

<br>

> It communicates **global** (with respect to the *entire* explained model)
> **feature influence**.

## Toy Example -- Numerical Feature

```{python}
#| echo: false
#| output: false

# Generate PD
ice_pd_num = []
for i in range(X_num.shape[1]):
    ice_pd_ = sklearn.inspection.partial_dependence(
        clf_num, X_num, features=[i],
        feature_names=feature_names,
        percentiles=(0, 1), grid_resolution=500,
        response_method='predict_proba', kind='both')
    ice_pd_num.append(ice_pd_)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for a numerical feature
#| fig-width: 55%

class_id = 0
feature_id = 2

plt.style.use('default')
with plt.xkcd():
  fig, ax = plt.subplots(figsize=(8, 4))
  fig.patch.set_alpha(0)

  plt.plot(ice_pd_num[feature_id]['values'][0],
           ice_pd_num[feature_id]['average'][class_id])

  plt.xlabel(f'{feature_names[feature_id]} value'.upper())

  plt.ylabel(f'{target_names[class_id]} probability'.upper())
  ax.yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')
  # ax.set_yticklabels([f'{100*item:2.0f}%' for item in ax.get_yticks()])

  plt.title(f'PD of the Iris data set'.upper())

plt.show()
plt.style.use('seaborn')
update_colours()
```

## Toy Example -- Categorical Feature

```{python}
#| echo: false
#| output: false

# Generate PD
ice_pd_cat = sklearn.inspection.partial_dependence(
    clf_cat, X_cat, features=[3],
    feature_names=feature_names,
    percentiles=(0, 1), grid_resolution=500,
    response_method='predict_proba', kind='both')
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for a categorical feature
#| fig-width: 55%

class_id = 0
feature_id = 3

plt.style.use('default')
with plt.xkcd():
  fig, ax = plt.subplots(figsize=(8, 4))
  fig.patch.set_alpha(0)

  plt.scatter(ice_pd_cat['values'][0], ice_pd_cat['average'][class_id],
              zorder=5, marker='X', s=100)

  plt.xlabel(f'{feature_names[feature_id][:-5]} category'.upper())
  plt.xticks([0, 1, 2])
  ax.xaxis.set_major_formatter(lambda f, pos: f'{cat_map[f]}')

  plt.ylabel(f'{target_names[class_id]} probability'.upper())
  ax.yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')
  #ax.set_yticklabels([f'{100*item:2.0f}%' for item in ax.get_yticks()])

  plt.title(f'PD of the Iris data set'.upper())

plt.show()
plt.style.use('seaborn')
update_colours()
```

::: {.notes}
- Sometimes you will see this visualised as a bar chart.
- You could also use box plots.
:::

## Method Properties

<br>

| *Property*           | **Partial Dependence**                                |
|----------------------|-------------------------------------------------------|
| *relation*           | post-hoc                                              |
| *compatibility*      | model-agnostic                                        |
| *modelling*          | regression, crisp and probabilistic classification    |
| *scope*              | global (per data set; generalises to cohort)          |
| *target*             | model (set of predictions)                            |

## Method Properties {{< meta subs.ctd >}}

<br>

| *Property*           | **Partial Dependence**                                |
|----------------------|-------------------------------------------------------|
| *data*               | tabular                                               |
| *features*           | numerical and categorical                             |
| *explanation*        | feature influence (visualisation)                     |
| *caveats*            | feature correlation, unrealistic instances, heterogeneous model response |

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# (Algorithmic) Building Blocks

## Computing PD

<br>

::: {.callout-note}
## Input

1. Select a **feature to explain**
2. Select the **explanation target**

    * crisp classifiers &rarr; one(-vs.-the-rest) or all classes
    * probabilistic classifiers &rarr; (probabilities of) one class
    * regressors &rarr; numerical values

3. Select a **collection of instances** to generate the explanation
:::

## Computing PD {{< meta subs.ctd >}}

<br>

::: {.callout-caution}
## Parameters

1. Define **granularity** of the explained feature

    * numerical attributes &rarr; select the range -- minimum and maximum
      value -- and the step size of the feature
    * categorical attributes &rarr; the full set or a subset of possible values
:::

## Computing PD {{< meta subs.ctd >}}

<br>

::: {.callout-tip}
## Procedure

1. For each instance in the designated data set create its copy with the value
   of the explained feature replaced by the range of values determined by the
   explanation granularity
2. Predict the augmented data
3. Generate and plot *Partial Dependence*

    * for **crisp classifiers** count the number of each unique prediction
      at each value of the explained feature across all the instances;
      visualise PD either as a *count* or *proportion* using separate line
      for each class or using a stacked bar chart
    * for probabilistic classifiers (per class) and regressors average the
      response of the model at each value of the explained feature across all
      the instances;
      visualise PD as a line

{{< fa star >}}&nbsp;&nbsp;&nbsp; Since the values of the explained feature may
**not be uniformly distributed** in the underlying data set,
a **rug plot** showing the distribution of its feature values can help in
interpreting the explanation.
:::

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Theoretical Underpinning

## Formulation &nbsp;&nbsp;&nbsp;{{< fa square-root-alt >}}

$$
X_{\mathit{PD}} \subseteq \mathcal{X}
$$

$$
V_i = \{ v_i^{\mathit{min}} , \ldots , v_i^{\mathit{max}} \}
$$

$$
\mathit{PD}_i =
\mathbb{E}_{X_{\setminus i}} \left[ f \left( X_{\setminus i} , x_i=v_i \right) \right] =
\int f \left( X_{\setminus i} , x_i=v_i \right) \; d \mathbb{P} ( X_{\setminus i} )
\;\; \forall \; v_i \in V_i
$$

<br>

$$
\mathit{PD}_i =
\mathbb{E}_{X_{\setminus i}} \left[ f \left( X_{\setminus i} , x_i=V_i \right) \right] =
\int f \left( X_{\setminus i} , x_i=V_i \right) \; d \mathbb{P} ( X_{\setminus i} )
$$

## Formulation &nbsp;&nbsp;&nbsp;{{< fa square-root-alt >}} {{< meta subs.ctd >}}

<br>

Based on the ICE notation [@goldstein2015peeking]

<br>

$$
\left\{ \left( x_{S}^{(i)} , x_{C}^{(i)} \right) \right\}_{i=1}^N
$$

<br>

$$
\hat{f}_S =
\mathbb{E}_{X_{C}} \left[ \hat{f} \left( x_{S} , X_{C} \right) \right] =
\int \hat{f} \left( x_{S} , X_{C} \right) \; d \mathbb{P} ( X_{C} )
$$

::: {.notes}
- $x_S$ is **stepped** through -- the explained feature
- $x_C$ are the **given** feature values
- $X_C$ is the **random variable**

- Marginalising the predictions over the distribution of the **given**
  features yields dependence between the explained feature(s)
  (*including any interactions*) and predictions.
:::

## Approximation &nbsp;&nbsp;&nbsp;{{< fa desktop >}}

<br>

(Monte Carlo approximation)

<br>

$$
\mathit{PD}_i \approx
\frac{1}{|X_{\mathit{PD}}|} \sum_{x \in X_{\mathit{PD}}}
f \left( x_ {\setminus i} , x_i=v_i \right)
$$

<br>

$$
\hat{f}_S \approx
\frac{1}{N} \sum_{i = 1}^N
\hat{f} \left( x_{S} , x_{C}^{(i)} \right)
$$

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Variants #

## Centred PD

<br>

> Centres PD curve by anchoring it at a fixed point,
> usually the lower end of the explained feature range.
> It is helpful when working with
> [{{< fa person-chalkboard >}} Centred ICE](ice.html#/centred-ice).

$$
\mathbb{E}_{X_{\setminus i}} \left[ f \left( X_{\setminus i} , x_i=V_i \right) \right] -
\mathbb{E}_{X_{\setminus i}} \left[ f \left( X_{\setminus i} , x_i=v_i^{\mathit{min}} \right) \right]
$$

<p style="text-align: center;">or</p>

$$
\mathbb{E}_{X_{C}} \left[ \hat{f} \left( x_{S}^{(i)} , X_{C} \right) \right] -
\mathbb{E}_{X_{C}} \left[ \hat{f} \left( x^{\star} , X_{C} \right) \right]
$$

::: {.notes}
- Helps to see whether the underlying ICE curves of individual instances
  behave differently.
:::

## PD-based Feature Importance

<br>

> Importance of a feature can be derived from a PD curve by assessing its
> **flatness** [@greenwell2018simple].
> A flat PD line indicates that the model is not overly sensitive to the
> values of the selected feature, hence it is not important for the model's
> decisions.

<br><br>

::: {.callout-important}
## Caveat

Similar to PD plots, this formulation of feature importance
**will not capture heterogeneity of individual instances**
that underlie the PD calculation.
:::

## PD-based Feature Importance {{< meta subs.ctd >}}

<br>

For example, for numerical features, it can be defined as
the (standard) deviation of PD measurement for each unique value of
the explained feature from the average PD.

<br>

$$
I_{\mathit{PD}} (i) = \sqrt{
    \frac{1}{|V_i| - 1}
    \sum_{v_i \in V_i} \left(
        \mathit{PD}_i - \underbrace{
            \frac{1}{|V_i|}
            \sum_{v_i \in V_i} \mathit{PD}_i
        }_{\text{average PD}}
    \right)^2
}
$$

## PD-based Feature Importance {{< meta subs.ctd >}}

<br>

For categorical features, it can be defined as
the **range statistic divided by four** (range rule)
of PD values, which provides a rough estimate of the standard deviation.

<br>

$$
I_{\mathit{PD}} (i) = \frac{
    \max_{V_i} \; \mathit{PD}_i - \min_{V_i} \; \mathit{PD}_i
}{
    4
}
$$

<br>

::: {.callout-tip}
## Formula

For the *normal distribution*, 95% of data is within
&plusmn;2 standard deviations.
Assuming a relatively small sample size, the range is likely to come
from within this 95% interval.
Therefore, the range divided by 4 roughly (under)estimates
the standard deviation.
:::

## PD-based Feature Importance {{< meta subs.ctd >}}

<br>

Based on the ICE notation [@goldstein2015peeking], where $K$ is the number of
unique values $x_S^{(k)}$ of the explained feature $x_S$

<br>

$$
I_{\mathit{PD}} (x_S) = \sqrt{
    \frac{1}{K - 1}
    \sum_{k=1}^K \left(
        \hat{f}_S(x^{(k)}_S) - \underbrace{
            \frac{1}{K}
            \sum_{k=1}^K \hat{f}_S(x^{(k)}_S)
        }_{\text{average PD}}
    \right)^2
}
$$

$$
I_{\mathit{PD}} (x_S) = \frac{
    \max_{k} \; \hat{f}_S(x^{(k)}_S) - \min_{k} \; \hat{f}_S(x^{(k)}_S)
}{
    4
}
$$

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Examples

## PD

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 2

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(ice_pd_num[feature_id]['values'][0],
         ice_pd_num[feature_id]['average'][class_id])

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## PD with Standard Deviation

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD (with standard deviation) for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 2

ice_pd_num_std = np.std(ice_pd_num[feature_id]['individual'][class_id], axis=0)

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['average'][class_id])
plt.fill_between(
    ice_pd_num[feature_id]['values'][0],
    (ice_pd_num[feature_id]['average'][class_id] - ice_pd_num_std),
    (ice_pd_num[feature_id]['average'][class_id] + ice_pd_num_std),
    color=line_colour,
    alpha=.33)

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## PD with ICE

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD (with ICE) for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 2

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['average'][class_id],
    lw=2, zorder=10)
plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['individual'][class_id].T,
    alpha=.05, c=other_colour, zorder=0)

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## PD with Standard Deviation & ICE

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD (with standard deviation & ICE) for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 2

ice_pd_num_std = np.std(ice_pd_num[feature_id]['individual'][class_id], axis=0)

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['average'][class_id],
    lw=2, zorder=10)
plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['individual'][class_id].T,
    alpha=.05, c=other_colour, zorder=0)
plt.fill_between(
    ice_pd_num[feature_id]['values'][0],
    (ice_pd_num[feature_id]['average'][class_id] - ice_pd_num_std),
    (ice_pd_num[feature_id]['average'][class_id] + ice_pd_num_std),
    color=line_colour,
    alpha=.25, zorder=5)

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## Centred PD (with Standard Deviation & ICE)

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Centred PD (with standard deviation & ICE) for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 2

cice_num_y = (
    ice_pd_num[feature_id]['individual'][class_id].T
    - ice_pd_num[feature_id]['individual'][class_id][:, 0])
cpd_num_y = np.average(cice_num_y, axis=1)
cpd_num_std = np.std(cice_num_y, axis=1)

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'Centred PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    cpd_num_y,
    lw=2, zorder=10)
plt.plot(
    ice_pd_num[feature_id]['values'][0],
    cice_num_y,
    alpha=.05, c=other_colour, zorder=0)
plt.fill_between(
    ice_pd_num[feature_id]['values'][0],
    (cpd_num_y - cpd_num_std),
    (cpd_num_y + cpd_num_std),
    color=line_colour,
    alpha=.25, zorder=5)

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## PD for Two (Numerical) Features

```{python}
#| echo: false
#| output: false

features_2d = [0, 1]
class_id = 0

ice_pd_2d = sklearn.inspection.partial_dependence(
    clf_num, X_num, features=features_2d,
    feature_names=feature_names,
    percentiles=(0, 1), grid_resolution=500,
    response_method='predict_proba', kind='average')
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Two-dimensional PD for the Iris data set
#| fig-width: 55%

plt.style.use('seaborn')
update_colours()

fig, ax = plt.subplots(  # 12 x 6
    2, 3, figsize=(12.25, 6.75), height_ratios=[6, .75], width_ratios=[.75, 11, .5])
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=.0, hspace=.0)

plt.sca(ax[0, 1])
plt.gca().grid(False)
im = plt.gca().imshow(np.flipud(ice_pd_2d['average'][class_id].T),
               alpha=0.5, cmap='cool', aspect='auto')

plt.gca().tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)
plt.gca().tick_params(
    axis='y', which='both', left=False, right=False, labelleft=False)

plt.title('Two-dimensional PD for the Iris data set')

plt.colorbar(
    im, cax=ax[0, 2],
    label=f'{target_names[class_id]} probability', orientation='vertical')

# Rug plot X
plt.sca(ax[1, 1])

kde1 = scipy.stats.gaussian_kde(X_num[:, features_2d[0]])
rug_x = np.linspace(
    X_num[:, features_2d[0]].min(),
    X_num[:, features_2d[0]].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, features_2d[0]], [0]*len(X_num[:, features_2d[0]]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

#plt.gca().set_xticks(
#    np.arange(ice_pd_2d['values'][0].shape[0], step=3),
#    labels=[f'{v:1.1f}' for i, v in enumerate(ice_pd_2d['values'][0]) if not i%3])
plt.xlim([ice_pd_2d['values'][0].min(), ice_pd_2d['values'][0].max()])
plt.xlabel(f'{feature_names[features_2d[0]]} value')

plt.gca().tick_params(
    axis='y', which='both', left=False, right=False, labelleft=False)
plt.gca().invert_yaxis()

# Rug plot Y
plt.sca(ax[0, 0])

kde2 = scipy.stats.gaussian_kde(X_num[:, features_2d[1]])
rug_y = np.linspace(
    X_num[:, features_2d[1]].min(),
    X_num[:, features_2d[1]].max(),
    num=200)
plt.plot(kde2(rug_y), rug_y, '-', alpha=.25)
plt.fill_betweenx(rug_y, kde2(rug_y), alpha=.25, zorder=5)

plt.scatter(
    [0]*len(X_num[:, features_2d[1]]), X_num[:, features_2d[1]],
    c='k', marker='_', s=100, alpha=.33, zorder=10)

#plt.gca().set_yticks(
#    np.arange(ice_pd_2d['values'][1].shape[0], step=3),
#    labels=[f'{v:1.1f}' for i, v in enumerate(ice_pd_2d['values'][1]) if not i%3][::-1])
plt.ylim([ice_pd_2d['values'][1].min(), ice_pd_2d['values'][1].max()])
plt.ylabel(f'{feature_names[features_2d[1]]} value')

plt.gca().tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)
plt.gca().invert_xaxis()

fig.delaxes(ax[1, 0])
fig.delaxes(ax[1, 2])
fig.tight_layout()

plt.show()

plt.style.use('seaborn')
update_colours()
```

## PD for Crisp Classifiers

```{python}
#| echo: false
#| output: false

class_id = 0
feature_id = 2

clf_num_crisp = sklearn.svm.SVC(probability=False)
clf_num_crisp.fit(X_num, y_num)
# trick partial dependence into taking crisp predictions
clf_num_crisp.predict_proba = clf_num_crisp.predict

ice_pd_crisp = sklearn.inspection.partial_dependence(
    clf_num_crisp, X_num, features=[feature_id],
    feature_names=feature_names,
    percentiles=(0, 1), grid_resolution=500,
    response_method='predict_proba', kind='both')

total_count = ice_pd_crisp['individual'][0].shape[0]
pd_count = []
for c in range(ice_pd_crisp['individual'][0].shape[1]):
    pd_count_ = [0, 0, 0]
    elems, counts = np.unique(
        ice_pd_crisp['individual'][0][:, c], return_counts=True)
    for i, j in zip(elems, counts):
        pd_count_[i] += j
    pd_count.append(pd_count_)
pd_count = np.array(pd_count)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Crisp classification PD for the Iris data set
#| fig-width: 55%

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

for i in range(pd_count.shape[1]):
    plt.plot(ice_pd_crisp['values'][0],
             pd_count[:, i],
             label=f'{target_names[i]}',
             alpha=.5)
plt.legend(loc='center right', frameon=True, fancybox=True, labelcolor='black', framealpha=.5)

plt.ylabel('prediction count')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## PD for Crisp Classifiers {{< meta subs.ctd >}}

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Crisp classification PD for the Iris data set
#| fig-width: 55%

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

width = .1
plt.bar(ice_pd_crisp['values'][0], pd_count[:, 0], width,
        label=f'{target_names[0]}')
plt.bar(ice_pd_crisp['values'][0], pd_count[:, 1], width,
        bottom=pd_count[:, 0], label=f'{target_names[1]}')
plt.bar(ice_pd_crisp['values'][0], pd_count[:, 2], width,
        bottom=pd_count[:, 1], label=f'{target_names[2]}')

plt.legend(loc='upper right', frameon=True, fancybox=True, labelcolor='black', framealpha=.5)

plt.ylabel('prediction count')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

::: {.notes}
- Gaps are there because scikit-learn does not sample the explained feature
  uniformly.
:::

## PD-based Feature Importance

```{python}
#| echo: false
#| output: false

class_id = 0

i_pd = []
for fid in range(X_num.shape[1]):
    i_pd_mean = np.mean(ice_pd_num[fid]['average'][class_id])
    i_pd_items = ice_pd_num[fid]['average'][class_id].shape[0]
    i_pd_ = 0
    for i in range(i_pd_items):
        i_pd_ += (ice_pd_num[fid]['average'][class_id][i] - i_pd_mean)**2
    i_pd_ /= i_pd_items - 1
    i_pd_ = np.sqrt(i_pd_)
    i_pd.append(i_pd_)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD-based feature importance for the Iris data set
#| fig-width: 55%

fig, ax = plt.subplots(figsize=(6, 4))
fig.patch.set_alpha(0)

plt.title(f'PD-based feature importance for the Iris data set')

x_ = list(range(len(i_pd)))
plt.bar(x_, i_pd, .5)

ax.set_xticks(x_, labels=feature_names)

plt.ylabel('feature importance')

plt.show()
```

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Case Studies & Gotchas!

## Out-of-distribution (Impossible) Instances

```{python}
#| echo: false
#| output: false

feature_id = 1

density = sklearn.neighbors.KernelDensity(kernel='gaussian', bandwidth=0.5)
density.fit(X_num)

density_scores = np.zeros(
    (X_num.shape[0], ice_pd_num[feature_id]['values'][class_id].shape[0]),
    dtype=np.float64)
for i in range(X_num.shape[0]):
    instances = np.repeat(
        X_num[[i], :],
        ice_pd_num[feature_id]['values'][class_id].shape[0],
        axis=0)
    instances[:, feature_id] = ice_pd_num[feature_id]['values'][class_id]
    density_scores[i, :] = np.exp(density.score_samples(instances))

density_x = np.arange(X_num.shape[0])
density_x = np.repeat(
    [density_x],
    ice_pd_num[feature_id]['values'][class_id].shape[0],
    axis=0)

density_y = np.repeat(
    np.array([ice_pd_num[feature_id]['values'][class_id]]).T,
    X_num.shape[0],
    axis=1)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Likelihood of PD instances belonging to the Iris data set
#| fig-width: 55%

plt.style.use('default')
update_colours()

fig, ax = plt.subplots(figsize=(12, 6))
fig.patch.set_alpha(0)

im = ax.imshow(np.flipud(density_scores.T), alpha=0.5, cmap='cool')

ax.xaxis.set_major_formatter(lambda f, pos: f'#{f:.0f}')
plt.xlabel('instance ID')

ax.set_yticks(
    np.arange(ice_pd_num[feature_id]['values'][class_id].shape[0], step=3),
    labels=[f'{v:1.1f}' for i, v in
            enumerate(ice_pd_num[feature_id]['values'][class_id])
            if not i%3][::-1])
plt.ylabel(f'{feature_names[feature_id]} value')

plt.title('Likelihood of the instance belonging to the Iris data set')

fig.tight_layout()
plt.show()

plt.style.use('seaborn')
update_colours()
```

::: aside
For more exmaples see the
[{{< fa person-chalkboard >}} *Out-of-distribution (Impossible) Instances*](ice.html#/out-of-distribution-impossible-instances)
topic for ICE.
:::

## Feature Correlation

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: Iris feature correlation
#| fig-width: 55%

X_num_corr = np.flipud(np.corrcoef(X_num, rowvar=False))

plt.style.use('default')
update_colours()

fig, ax = plt.subplots()
fig.patch.set_alpha(0)

im = ax.imshow(np.abs(X_num_corr), vmin=0, vmax=1, alpha=.5, cmap='bwr')

# Show all ticks and label them with the respective list entries
ax.set_xticks(np.arange(len(feature_names)), labels=feature_names)
ax.set_yticks(np.arange(len(feature_names)), labels=feature_names[::-1])

# Rotate the tick labels and set their alignment.
plt.setp(ax.get_xticklabels(), rotation=15, ha='right',
         rotation_mode='anchor')
plt.setp(ax.get_yticklabels(), rotation=0, ha='right',
         rotation_mode='anchor')

# Loop over data dimensions and create text annotations.
for i in range(len(feature_names)):
    for j in range(len(feature_names)):
        text = ax.text(j, i, f'{X_num_corr[i, j]:1.2f}',
                       ha='center', va='center', color='k')

ax.set_title('Correlation coefficient between Iris features')
fig.tight_layout()
plt.show()

plt.style.use('seaborn')
update_colours()
```

## Feature Correlation {{< meta subs.ctd >}}

```{python}
#| echo: false
#| output: false

class_id = 0
features = [1, 0]
correlation = 'small'

clf_num_linear_s = sklearn.svm.SVC(probability=True, kernel='linear')
clf_num_linear_s.fit(X_num[:, features], y_num)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for all features of a single class
#| fig-width: 55%

fig, ax = plt.subplots(
    2, 2, figsize=(18, 4.5), height_ratios=[4, .5])
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=.01, hspace=.01)
fig.suptitle('PD for all instances of the Iris data set for the '
             f'(probability of) {target_names[class_id]} class\n'
             f'(features #{features[0] + 1} & #{features[1] + 1} '
             f'\u2013 {correlation} correlation)')
fig.subplots_adjust(top=.89)

for feature_id_cut, feature_id_full in enumerate(features):

    ice_pd_num_s = sklearn.inspection.partial_dependence(
        clf_num_linear_s, X_num[:, features], features=[feature_id_cut],
        percentiles=(0, 1), grid_resolution=500,
        response_method='predict_proba', kind='both')

    # PD
    plt.sca(ax[0][feature_id_cut])

    plt.plot(ice_pd_num_s['values'][0], ice_pd_num_s['average'][class_id],
            alpha=.25, c=line_colour)

    plt.gca().yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')
    plt.ylim((-0.1723, 1.0437))

    # rug plot
    plt.sca(ax[1][feature_id_cut])

    plt.xlabel(f'{feature_names[feature_id_full]} value')
    plt.yticks([])

    kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id_full])
    rug_x = np.linspace(
        X_num[:, feature_id_full].min(),
        X_num[:, feature_id_full].max(),
        num=200)
    plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
    plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

    plt.scatter(
        X_num[:, feature_id_full], [0]*len(X_num[:, feature_id_full]),
        c='k', marker='|', s=100, alpha=.33, zorder=10)

ax[0][0].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)
ax[0][1].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)

ax[0][1].tick_params(
    axis='y', which='both', left=False, right=False, labelleft=False)

ax[0][0].sharex(ax[1][0])
ax[0][1].sharex(ax[1][1])

ax[0][0].sharey(ax[0][1])

plt.show()
```

::: aside
:::

## Feature Correlation {{< meta subs.ctd >}}

```{python}
#| echo: false
#| output: false

class_id = 0
features = [1, 2]
correlation = 'small'

clf_num_linear_s = sklearn.svm.SVC(probability=True, kernel='linear')
clf_num_linear_s.fit(X_num[:, features], y_num)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for all features of a single class
#| fig-width: 55%

fig, ax = plt.subplots(
    2, 2, figsize=(18, 4.5), height_ratios=[4, .5])
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=.01, hspace=.01)
fig.suptitle('PD for all instances of the Iris data set for the '
             f'(probability of) {target_names[class_id]} class\n'
             f'(features #{features[0] + 1} & #{features[1] + 1} '
             f'\u2013 {correlation} correlation)')
fig.subplots_adjust(top=.89)

for feature_id_cut, feature_id_full in enumerate(features):

    ice_pd_num_s = sklearn.inspection.partial_dependence(
        clf_num_linear_s, X_num[:, features], features=[feature_id_cut],
        percentiles=(0, 1), grid_resolution=500,
        response_method='predict_proba', kind='both')

    # PD
    plt.sca(ax[0][feature_id_cut])

    plt.plot(ice_pd_num_s['values'][0], ice_pd_num_s['average'][class_id],
            alpha=.25, c=line_colour)

    plt.gca().yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')
    plt.ylim((-0.1723, 1.0437))

    # rug plot
    plt.sca(ax[1][feature_id_cut])

    plt.xlabel(f'{feature_names[feature_id_full]} value')
    plt.yticks([])

    kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id_full])
    rug_x = np.linspace(
        X_num[:, feature_id_full].min(),
        X_num[:, feature_id_full].max(),
        num=200)
    plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
    plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

    plt.scatter(
        X_num[:, feature_id_full], [0]*len(X_num[:, feature_id_full]),
        c='k', marker='|', s=100, alpha=.33, zorder=10)

ax[0][0].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)
ax[0][1].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)

ax[0][1].tick_params(
    axis='y', which='both', left=False, right=False, labelleft=False)

ax[0][0].sharex(ax[1][0])
ax[0][1].sharex(ax[1][1])

ax[0][0].sharey(ax[0][1])

plt.show()
```

::: aside
:::

## Feature Correlation {{< meta subs.ctd >}}

```{python}
#| echo: false
#| output: false

class_id = 0
features = [1, 3]
correlation = 'small'

clf_num_linear_s = sklearn.svm.SVC(probability=True, kernel='linear')
clf_num_linear_s.fit(X_num[:, features], y_num)
```

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for all features of a single class
#| fig-width: 55%

fig, ax = plt.subplots(
    2, 2, figsize=(18, 4.5), height_ratios=[4, .5])
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=.01, hspace=.01)
fig.suptitle('PD for all instances of the Iris data set for the '
             f'(probability of) {target_names[class_id]} class\n'
             f'(features #{features[0] + 1} & #{features[1] + 1} '
             f'\u2013 {correlation} correlation)')
fig.subplots_adjust(top=.89)

for feature_id_cut, feature_id_full in enumerate(features):

    ice_pd_num_s = sklearn.inspection.partial_dependence(
        clf_num_linear_s, X_num[:, features], features=[feature_id_cut],
        percentiles=(0, 1), grid_resolution=500,
        response_method='predict_proba', kind='both')

    # PD
    plt.sca(ax[0][feature_id_cut])

    plt.plot(ice_pd_num_s['values'][0], ice_pd_num_s['average'][class_id],
            alpha=.25, c=line_colour)

    plt.gca().yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')
    plt.ylim((-0.1723, 1.0437))

    # rug plot
    plt.sca(ax[1][feature_id_cut])

    plt.xlabel(f'{feature_names[feature_id_full]} value')
    plt.yticks([])

    kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id_full])
    rug_x = np.linspace(
        X_num[:, feature_id_full].min(),
        X_num[:, feature_id_full].max(),
        num=200)
    plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
    plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

    plt.scatter(
        X_num[:, feature_id_full], [0]*len(X_num[:, feature_id_full]),
        c='k', marker='|', s=100, alpha=.33, zorder=10)

ax[0][0].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)
ax[0][1].tick_params(
    axis='x', which='both', top=False, bottom=False, labelbottom=False)

ax[0][1].tick_params(
    axis='y', which='both', left=False, right=False, labelleft=False)

ax[0][0].sharex(ax[1][0])
ax[0][1].sharex(ax[1][1])

ax[0][0].sharey(ax[0][1])

plt.show()
```

::: aside
For more exmaples see the
[{{< fa person-chalkboard >}} *Feature Correlation*](ice.html#/feature-correlation)
topic for ICE.
:::

## Heterogeneous Influence

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 3

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['average'][class_id],
    lw=2, zorder=10)
plt.ylim((-0.1723, 1.0437))

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

## Heterogeneous Influence {{< meta subs.ctd >}}

```{python}
#| echo: false
#| fig-align: center
#| fig-alt: PD (with standard deviation & ICE) for the Iris data set
#| fig-width: 55%

class_id = 0
feature_id = 3

ice_pd_num_std = np.std(ice_pd_num[feature_id]['individual'][class_id], axis=0)

fig, ax = plt.subplots(2, 1, figsize=(8, 4.5), height_ratios=[4, .5], sharex=True)
fig.patch.set_alpha(0)
plt.subplots_adjust(wspace=0, hspace=.05)

# PD
plt.sca(ax[0])

plt.title(f'PD for the Iris data set')

plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['average'][class_id],
    lw=2, zorder=10)
plt.plot(
    ice_pd_num[feature_id]['values'][0],
    ice_pd_num[feature_id]['individual'][class_id].T,
    alpha=.05, c=other_colour, zorder=0)
plt.fill_between(
    ice_pd_num[feature_id]['values'][0],
    (ice_pd_num[feature_id]['average'][class_id] - ice_pd_num_std),
    (ice_pd_num[feature_id]['average'][class_id] + ice_pd_num_std),
    color=line_colour,
    alpha=.25, zorder=5)
plt.ylim((-0.1723, 1.0437))

plt.ylabel(f'{target_names[class_id]} probability')
ax[0].yaxis.set_major_formatter(lambda f, pos: f'{100*f:2.0f}%')

# rug plot
plt.sca(ax[1])

plt.xlabel(f'{feature_names[feature_id]} value')
plt.yticks([])

kde1 = scipy.stats.gaussian_kde(X_num[:, feature_id])
rug_x = np.linspace(
    X_num[:, feature_id].min(),
    X_num[:, feature_id].max(),
    num=200)
plt.plot(rug_x, kde1(rug_x), '-', alpha=.25)
plt.fill_between(rug_x, kde1(rug_x), alpha=.25, zorder=5)

plt.scatter(
    X_num[:, feature_id], [0]*len(X_num[:, feature_id]),
    c='k', marker='|', s=100, alpha=.33, zorder=10)

plt.show()
```

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Properties

## Pros &nbsp;&nbsp;&nbsp;{{< fa plus-square >}}

- **Easy to generate and interpret**
- Can be **derived from ICEs**
- Can be used to **compute feature importance**

## Cons &nbsp;&nbsp;&nbsp;{{< fa minus-square >}}

- Assumes **feature independence**, which is often unreasonable
- PD may not reflect the true behaviour of the model since it based upon
  the behaviour of the model for **unrealistic instances**
- May be **unreliable for certain values** of the explained feature when its
  values are not uniformly distributed (abated by a **rug plot**)
- Limited to explaining **two feature at a time**

- Does not capture the diversity (heterogeneity) of the model's behaviour for
  the individual instances used for PD calculation
  (abated by displaying the underlying **ICE lines**)

## Caveats &nbsp;&nbsp;&nbsp;{{< fa skull >}}

- PD is derived by averaging ICEs
- Generating PD may be computationally expensive for *large sets of data* and
  *wide feature intervals* with a *small "inspection" step*
- Computational complexity: $\mathcal{O} \left( n \times d \right)$, where
  * $n$ is the number of instances in the designated data set and
  * $d$ is the number of steps within the designated feature interval

<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->

# Further Considerations

## Causal Interpretation

<br>

@zhao2021causal noticed similarity in the formulation of Partial Dependence
and Pearl's back-door criterion [@pearl2016causal], allowing for
a causal interpretation of PD under quite restrictive assumptions:

* the explained predictive model is a good (truthful) approximation of
  the underlying data generation process;
* detailed domain knowledge is available, allowing us to assess the causal
  structure of the problem and verify the back-door criterion (see below); and
* the set of features **complementary** to the explained attribute satisfies
  the back-door criterion, i.e., none of the complementary features are
  **causal descendant** of the explained attribute.

## Causal Interpretation {{< meta subs.ctd >}}

<br>

By interveening on the explained feature, we measure the change in
the model's output, allowing us to analyse the causal relationship
between the two.

<br><br>

::: {.callout-important}
## Caveat

In principle, the causal relationship is with respect to the explained model,
and not the underlying phenomenon (that generates the data).
:::

## Related Techniques

<br>

### Individual Conditional Expectation (ICE)

> [{{< fa person-chalkboard >}}](ice.html) &nbsp;&nbsp;&nbsp;
> Instance-focused (local) "version" of *Partial Dependence*,
> which communicates the influence of a specific feature value on
> the model's prediction by **fixing the value of this feature**
> for a single data point [@goldstein2015peeking].

## Related Techniques {{< meta subs.ctd >}}

<br>

### Marginal Effect (Marginal Plots or M-Plots)

> [{{< fa person-chalkboard >}}](m.html) &nbsp;&nbsp;&nbsp;
> It communicates the influence of a specific feature value
> -- or similar values, i.e., an interval around the selected value --
> on the model's prediction by **only considering relevant instances**
> found in the designated data set.
> It is calculated as **the average prediction of these instances**.

## Related Techniques {{< meta subs.ctd >}}

<br>

### Accumulated Local Effect (ALE)

> [{{< fa person-chalkboard >}}](ale.html) &nbsp;&nbsp;&nbsp;
> It communicates the influence of a specific feature value on the model's
> prediction by quantifying the average (accumulated) difference between
> the predictions at the boundaries of a (small) **fixed interval** around
> the selected feature value [@apley2020visualizing].
> It is calculated by replacing the value of the explained feature with the
> interval boundaries for **instances found in the designated data set**
> whose value of this feature is within the specified range.

## Implementations

| {{< fa brands python >}} Python          | {{< fa brands r-project >}} R     |
|:-----------------------------------------|:----------------------------------|
| [scikit-learn][sklearn-pdp] (`>=0.24.0`) | [iml]                             |
| [PyCEbox]                                | [ICEbox]                          |
| [PDPbox]                                 | [pdp]                             |
| [InterpretML]                            | [DALEX]                           |
| [Skater]                                 |                                   |
| [alibi]                                  |                                   |

: {tbl-colwidths="[50,50]"}

## Further Reading

- [PD paper][pd-paper] [@friedman2001greedy]
- [*Interpretable Machine Learning* book][iml-book]
- [*Explanatory Model Analysis* book][ema-book]
- [Kaggle course][kaggle-course]
- [scikit-learn example][sklearn-example]
- FAT Forensics [example][fatf-example] and [tutorial][fatf-tutorial]
- InterpretML [example][interpretml-example]

## Bibliography

::: {#refs}
:::

---

[sklearn-pdp]: https://scikit-learn.org/stable/modules/generated/sklearn.inspection.partial_dependence.html
[PyCEbox]: https://github.com/AustinRochford/PyCEbox
[PDPbox]: https://github.com/SauceCat/PDPbox
[InterpretML]: https://github.com/interpretml/interpret
[Skater]: https://github.com/oracle/Skater
[iml]: https://github.com/christophM/iml
[ICEbox]: https://github.com/kapelner/ICEbox
[pdp]: https://github.com/bgreenwell/pdp
[DALEX]: https://github.com/ModelOriented/DALEX
[alibi]: https://github.com/SeldonIO/alibi

[pd-paper]: https://www.doi.org/10.1214/aos/1013203451
[iml-book]: https://christophm.github.io/interpretable-ml-book/pdp.html
[ema-book]: https://ema.drwhy.ai/partialDependenceProfiles.html
[kaggle-course]: https://www.kaggle.com/code/dansbecker/partial-plots
[sklearn-example]: https://scikit-learn.org/stable/auto_examples/inspection/plot_partial_dependence.html
[fatf-example]: https://fat-forensics.org/sphinx_gallery_auto/transparency/xmpl_transparency_pd.html
[fatf-tutorial]: https://fat-forensics.org/tutorials/model-explainability.html
[interpretml-example]: https://interpret.ml/docs/pdp.html
